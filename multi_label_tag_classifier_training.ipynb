{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.2"
    },
    "colab": {
      "name": "multi_label_tag_classifier_training.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S72wsuKieCVJ",
        "colab_type": "text"
      },
      "source": [
        "## CNN classifier for multi label tagging of Myntra fashion products"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wDUdzgI23vrO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Execute only in colab\n",
        "!pip uninstall tensorflow\n",
        "!pip install tensorflow==1.15.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ReM7RBLVxHdi",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import PIL\n",
        "import sys\n",
        "from matplotlib import pyplot\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import fbeta_score\n",
        "\n",
        "import keras\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from keras import backend\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Conv2D, MaxPooling2D, Dense, Flatten\n",
        "from keras.optimizers import SGD\n",
        "\n",
        "from keras.preprocessing.image import load_img, img_to_array\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bJo65ZZHpr65",
        "colab_type": "text"
      },
      "source": [
        "##### If you are working on your local computer. Download and extract the dataset from https://www.kaggle.com/paramaggarwal/fashion-product-images-small\n",
        "##### As the productDisplayName column in styles.csv needed modification. Extract only the images folder into your CNN_model_fashion_products_multi_label_tagging/images/ directory. Make use of styles.csv from this repository."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "met2wttxxV18",
        "colab_type": "code",
        "outputId": "0766d487-a527-47bb-b5aa-d609a2969b8a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "folder_path = os.getcwd()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Uninstalling tensorflow-2.2.0rc2:\n",
            "  Would remove:\n",
            "    /usr/local/bin/estimator_ckpt_converter\n",
            "    /usr/local/bin/saved_model_cli\n",
            "    /usr/local/bin/tensorboard\n",
            "    /usr/local/bin/tf_upgrade_v2\n",
            "    /usr/local/bin/tflite_convert\n",
            "    /usr/local/bin/toco\n",
            "    /usr/local/bin/toco_from_protos\n",
            "    /usr/local/lib/python3.6/dist-packages/tensorflow-2.2.0rc2.dist-info/*\n",
            "    /usr/local/lib/python3.6/dist-packages/tensorflow/*\n",
            "Proceed (y/n)? y\n",
            "  Successfully uninstalled tensorflow-2.2.0rc2\n",
            "Collecting tensorflow==1.15.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3f/98/5a99af92fb911d7a88a0005ad55005f35b4c1ba8d75fba02df726cd936e6/tensorflow-1.15.0-cp36-cp36m-manylinux2010_x86_64.whl (412.3MB)\n",
            "\u001b[K     |████████████████████████████████| 412.3MB 44kB/s \n",
            "\u001b[?25hRequirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (3.2.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (0.9.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (1.18.2)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (1.27.2)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (1.0.8)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (3.10.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (1.1.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (0.34.2)\n",
            "Collecting tensorflow-estimator==1.15.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/de/62/2ee9cd74c9fa2fa450877847ba560b260f5d0fb70ee0595203082dafcc9d/tensorflow_estimator-1.15.1-py2.py3-none-any.whl (503kB)\n",
            "\u001b[K     |████████████████████████████████| 512kB 52.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (0.2.0)\n",
            "Collecting tensorboard<1.16.0,>=1.15.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1e/e9/d3d747a97f7188f48aa5eda486907f3b345cd409f0a0850468ba867db246/tensorboard-1.15.0-py3-none-any.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8MB 68.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (1.12.1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (1.1.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (0.8.1)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (1.12.0)\n",
            "Collecting gast==0.2.2\n",
            "  Downloading https://files.pythonhosted.org/packages/4e/35/11749bf99b2d4e3cceb4d55ca22590b0d7c2c62b9de38ac4a4a7f4687421/gast-0.2.2.tar.gz\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow==1.15.0) (2.10.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow==1.15.0) (46.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (3.2.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (1.0.0)\n",
            "Building wheels for collected packages: gast\n",
            "  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gast: filename=gast-0.2.2-cp36-none-any.whl size=7540 sha256=85162e539d85ff470d825b59f02c269e74374e5ffb9df6d006def726673f94d7\n",
            "  Stored in directory: /root/.cache/pip/wheels/5c/2e/7e/a1d4d4fcebe6c381f378ce7743a3ced3699feb89bcfbdadadd\n",
            "Successfully built gast\n",
            "Installing collected packages: tensorflow-estimator, tensorboard, gast, tensorflow\n",
            "  Found existing installation: tensorflow-estimator 2.2.0rc0\n",
            "    Uninstalling tensorflow-estimator-2.2.0rc0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.2.0rc0\n",
            "  Found existing installation: tensorboard 2.2.0\n",
            "    Uninstalling tensorboard-2.2.0:\n",
            "      Successfully uninstalled tensorboard-2.2.0\n",
            "  Found existing installation: gast 0.3.3\n",
            "    Uninstalling gast-0.3.3:\n",
            "      Successfully uninstalled gast-0.3.3\n",
            "Successfully installed gast-0.2.2 tensorboard-1.15.0 tensorflow-1.15.0 tensorflow-estimator-1.15.1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "gast",
                  "tensorboard",
                  "tensorflow"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "anA0DGO7rIZO",
        "colab_type": "text"
      },
      "source": [
        "### Run below cell only in google colab\n",
        "##### Upload your kaggle.json file into colab before you run below cell.\n",
        "##### Download the kaggle.json file from your kaggle Profile/Account/API by clicking \"Create New API Token\"."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lWWcK0MweCVQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!git clone https://github.com/sharathrjtr/CNN_model_fashion_products_multi_label_tagging.git\n",
        "folder_path = os.path.join(folder_path, 'CNN_model_fashion_products_multi_label_tagging')\n",
        "\n",
        "# Download the Kaggle Myntra fashion products small dataset\n",
        "# For details: https://github.com/Kaggle/kaggle-api\n",
        "\n",
        "# Two methods to authenticate your kaggle account. \n",
        "\n",
        "# Method 1: Fill in the details of username and key below from the kaggle.json.\n",
        "# os.environ['KAGGLE_USERNAME'] = \"username\"\n",
        "# os.environ['KAGGLE_KEY'] = \"xxxxxxxxxxxxxx\"\n",
        "\n",
        "# Method 2: If kaggle.json is already uploaded in colab directory /content/\n",
        "os.environ['KAGGLE_CONFIG_DIR']='/content/'\n",
        "\n",
        "!kaggle datasets download -d paramaggarwal/fashion-product-images-small\n",
        "\n",
        "# Unzip the download dataset into the CNN model directory excluding the styles.csv and directory myntradataset/\n",
        "!unzip fashion-product-images-small.zip -x styles.csv -x myntradataset/* -d CNN_model_fashion_products_multi_label_tagging/myntradataset/\n",
        "\n",
        "colab = True\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "flJyg9rUeCVZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def cleanup_csv_mapping(mapping_csv):\n",
        "    # articleType can be used to find subCategory and masterCategory. \n",
        "    # Year specifies particular year the product is made, productDisplayName is something unique to the product and not a generalization.\n",
        "    # Hence, we are dropping masterCategory, subCartegory, year and productDisplayName columns from the data frame.\n",
        "    mapping_csv.drop(['masterCategory', 'subCategory', 'year', 'productDisplayName'], axis=1, inplace=True)\n",
        "\n",
        "    # Drop the samples which don't have any value in any of the columns.\n",
        "    mapping_csv.dropna(inplace=True)\n",
        "    mapping_csv.head()\n",
        "    \n",
        "    return mapping_csv"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "07CxqNIBeCVe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create a list of tags available among gender, articleType, baseColour, season and usage\n",
        "# generate a mapping from tags to integers and integers to tags\n",
        "def extract_tags_mapping(mapping_csv):\n",
        "    labels = set()\n",
        "    \n",
        "    for index, row in mapping_csv.iterrows():\n",
        "        fileid = row['id']\n",
        "        gender = row['gender']\n",
        "        article_type = row['articleType']\n",
        "        base_colour = row['baseColour']\n",
        "        season = row['season']\n",
        "        usage = row['usage']\n",
        "        \n",
        "        labels.update([gender, article_type, base_colour, season, usage])\n",
        "    print('Total labels:', len(labels))\n",
        "\n",
        "    # convert the labels to a list and sort them alphabetically\n",
        "    labels = list(labels)\n",
        "    # order set alphabetically\n",
        "    labels.sort()\n",
        "    \n",
        "    # create dictionary that maps labels to integers so that we can encode the training dataset for modeling.\n",
        "    # create a dictionary with reverse mapping from integers to string tag values, so later when the model makes a prediction, we can turn it into something readable.\n",
        "    labels_map = {labels[i]: i for i in range(len(labels))}\n",
        "    inv_labels_map = {i:labels[i] for i in range(len(labels))}\n",
        "    \n",
        "    return labels_map, inv_labels_map"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zXGLDtn8eCVi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# extract the training images filename and labels for all images.\n",
        "def extract_img_ids_labels(mapping_csv):\n",
        "    image_ids = []\n",
        "    image_labels = dict()\n",
        "    for index, row in mapping_csv.iterrows():\n",
        "        fileid = row['id']\n",
        "        gender = row['gender']\n",
        "        article_type = row['articleType']\n",
        "        base_colour = row['baseColour']\n",
        "        season = row['season']\n",
        "        usage = row['usage']\n",
        "        \n",
        "        if os.path.exists(folder_path+'/myntradataset/images/'+str(fileid)+'.jpg'):\n",
        "            image_ids.append(fileid)\n",
        "            image_labels[fileid] = [gender, article_type, base_colour, season, usage]\n",
        "    \n",
        "    print('Number of train files: ', len(image_ids))\n",
        "    \n",
        "    return image_ids, image_labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OSVoikLheCVm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create a one hot encoding for one list of tags\n",
        "def one_hot_encode(tags, mapping):\n",
        "    # create empty vector\n",
        "    encoding = np.zeros(len(mapping), dtype='uint8')\n",
        "    # mark 1 for each tag in the vector\n",
        "    for tag in tags:\n",
        "        encoding[mapping[tag]] = 1\n",
        "    return encoding"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wgcbWDOleCVr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load images and extract labels in one hot encode form\n",
        "def load_dataset(image_ids, image_labels, tag_mapping):\n",
        "    images, targets = list(), list()\n",
        "    # enumerate file in the directory\n",
        "    for filename in image_ids:\n",
        "        # load image\n",
        "        image = load_img(os.path.join(folder_path+'/myntradataset/images', str(filename)+'.jpg'), target_size=(60,80))\n",
        "        # convert to numpy array\n",
        "        image = img_to_array(image, dtype='uint8')\n",
        "        # get tags\n",
        "        tags = image_labels[filename]\n",
        "        # one hot encode tags\n",
        "        target = one_hot_encode(tags, tag_mapping)\n",
        "        # store train image and tags\n",
        "        images.append(image)\n",
        "        targets.append(target)\n",
        "    \n",
        "    X = np.asarray(images, dtype='uint8')\n",
        "    y = np.asarray(targets, dtype='uint8')\n",
        "    return X, y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pfd6W0PpeCVv",
        "colab_type": "code",
        "outputId": "4cf54157-ca46-4f33-cee6-40fbfc28f093",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        }
      },
      "source": [
        "csv_filename = folder_path+'/myntradataset/styles.csv'\n",
        "# Read the csv file and clean up the file to extract relevant data\n",
        "# productDisplayName column consist of extra commas for few row. \n",
        "# These were manually removed as it can result in error during reading of the file\n",
        "mapping_csv = pd.read_csv(csv_filename)\n",
        "print('Dataset Mapping dataframe size before cleanup: ', mapping_csv.shape)\n",
        "\n",
        "mapping_csv = cleanup_csv_mapping(mapping_csv)\n",
        "print('Dataset Mapping dataframe size after cleanup: ', mapping_csv.shape)\n",
        "mapping_csv.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dataset Mapping dataframe size before cleanup:  (44446, 10)\n",
            "Dataset Mapping dataframe size after cleanup:  (44101, 6)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>gender</th>\n",
              "      <th>articleType</th>\n",
              "      <th>baseColour</th>\n",
              "      <th>season</th>\n",
              "      <th>usage</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>15970</td>\n",
              "      <td>Men</td>\n",
              "      <td>Shirts</td>\n",
              "      <td>Navy Blue</td>\n",
              "      <td>Fall</td>\n",
              "      <td>Casual</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>39386</td>\n",
              "      <td>Men</td>\n",
              "      <td>Jeans</td>\n",
              "      <td>Blue</td>\n",
              "      <td>Summer</td>\n",
              "      <td>Casual</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>59263</td>\n",
              "      <td>Women</td>\n",
              "      <td>Watches</td>\n",
              "      <td>Silver</td>\n",
              "      <td>Winter</td>\n",
              "      <td>Casual</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>21379</td>\n",
              "      <td>Men</td>\n",
              "      <td>Track Pants</td>\n",
              "      <td>Black</td>\n",
              "      <td>Fall</td>\n",
              "      <td>Casual</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>53759</td>\n",
              "      <td>Men</td>\n",
              "      <td>Tshirts</td>\n",
              "      <td>Grey</td>\n",
              "      <td>Summer</td>\n",
              "      <td>Casual</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      id gender  articleType baseColour  season   usage\n",
              "0  15970    Men       Shirts  Navy Blue    Fall  Casual\n",
              "1  39386    Men        Jeans       Blue  Summer  Casual\n",
              "2  59263  Women      Watches     Silver  Winter  Casual\n",
              "3  21379    Men  Track Pants      Black    Fall  Casual\n",
              "4  53759    Men      Tshirts       Grey  Summer  Casual"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NwqL__UseCV0",
        "colab_type": "code",
        "outputId": "d2a6653f-001e-4730-8470-353ce1b19c94",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "# extract mapping from labels to indices and indices to labels\n",
        "labels_to_idx, idx_to_labels = extract_tags_mapping(mapping_csv)\n",
        "\n",
        "# extract the images filename and tags for training dataset\n",
        "train_ids, train_labels = extract_img_ids_labels(mapping_csv)\n",
        "\n",
        "# load the dataset, the actual images and labels for each image with one-hot encoding\n",
        "train_images, train_tags = load_dataset(train_ids, train_labels, labels_to_idx)\n",
        "print('Total Images shape: ', train_images.shape, 'Total tags shape: ', train_tags.shape)\n",
        "\n",
        "# Total size of image loaded will be about 60*80*3*44101*8 / (1000000000*8) = 0.635GB\n",
        "# save both arrays to one file in compressed format\n",
        "np.savez_compressed(folder_path+'/myntra_train_data.npz', train_images, train_tags)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total labels: 205\n",
            "Number of train files:  44096\n",
            "(44096, 60, 80, 3) (44096, 205)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "velcC-GOxrH8",
        "colab_type": "text"
      },
      "source": [
        "#### From here on we work on the saved mytra_train_data.npz file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IJmlHPJBeCV-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_saved_dataset():\n",
        "    data = np.load(folder_path+'/myntra_train_data.npz')\n",
        "    X, y = data['arr_0'], data['arr_1']\n",
        "    trainX, testX, trainY, testY = train_test_split(X, y, test_size = 0.3, random_state = 1)\n",
        "    print('Train images Shape: ', trainX.shape, 'Train labels shape:', trainY.shape)\n",
        "    print('Test images shape: ', testX.shape, 'Test labels shape: ', testY.shape)\n",
        "    \n",
        "    return trainX, trainY, testX, testY"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d_VD6DjKeCWB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " # calculate fbeta score for multi-class/label classification\n",
        "def fbeta(y_true, y_pred, beta=2):\n",
        "    # clip predictions\n",
        "    y_pred = keras.backend.clip(y_pred, 0, 1)\n",
        "    # calculate elements\n",
        "    tp = keras.backend.sum(keras.backend.round(keras.backend.clip(y_true * y_pred, 0, 1)), axis=1)\n",
        "    fp = keras.backend.sum(keras.backend.round(keras.backend.clip(y_pred - y_true, 0, 1)), axis=1)\n",
        "    fn = keras.backend.sum(keras.backend.round(keras.backend.clip(y_true - y_pred, 0, 1)), axis=1)\n",
        "    # calculate precision\n",
        "    p = tp / (tp + fp + keras.backend.epsilon())\n",
        "    # calculate recall\n",
        "    r = tp / (tp + fn + keras.backend.epsilon())\n",
        "    # calculate fbeta, averaged across each class\n",
        "    bb = beta ** 2\n",
        "    fbeta_score = keras.backend.mean((1 + bb) * (p * r) / (bb * p + r + keras.backend.epsilon()))\n",
        "    return fbeta_score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R36S3gfPeCWF",
        "colab_type": "code",
        "outputId": "164de05e-c9a7-4567-9f64-f0f326f35176",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "source": [
        "trainX, trainY, testX, testY = load_saved_dataset()\n",
        "\n",
        "# make all one predictions\n",
        "train_yhat = np.asarray([np.ones(trainY.shape[1]) for _ in range(trainY.shape[0])])\n",
        "test_yhat = np.asarray([np.ones(testY.shape[1]) for _ in range(testY.shape[0])])\n",
        "# evaluate predictions\n",
        "train_score = fbeta_score(trainY, train_yhat, 2, average='samples')\n",
        "test_score = fbeta_score(testY, test_yhat, 2, average='samples')\n",
        "print('All Ones: train=%.3f, test=%.3f' % (train_score, test_score))\n",
        "\n",
        "# evaluate predictions with keras\n",
        "train_score = fbeta(keras.backend.variable(trainY), keras.backend.variable(train_yhat))\n",
        "test_score = fbeta(keras.backend.variable(testY), keras.backend.variable(test_yhat))\n",
        "\n",
        "# if tensorflow_version > 1.15.0:\n",
        "#   print('All Ones (keras): train=%.3f, test=%.3f' % (train_score, test_score))\n",
        "# else:\n",
        "print('All Ones (keras): train=%.3f, test=%.3f' % (keras.backend.eval(train_score), keras.backend.eval(test_score)))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train images Shape:  (30867, 60, 80, 3) Train labels shape: (30867, 205)\n",
            "Test images shape:  (13229, 60, 80, 3) Test labels shape:  (13229, 205)\n",
            "All Ones: train=0.111, test=0.111\n",
            "All Ones (keras): train=0.111, test=0.111\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MBmV_pfQeCWJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define cnn model\n",
        "def define_baseline_model(in_shape=(60,80, 3), out_shape=205):\n",
        "    model = Sequential()\n",
        "    model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=in_shape))\n",
        "    model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "    model.add(MaxPooling2D((2, 2)))\n",
        "    model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "    model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "    model.add(MaxPooling2D((2, 2)))\n",
        "    model.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "    model.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "    model.add(MaxPooling2D((2, 2)))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n",
        "    model.add(Dense(out_shape, activation='sigmoid'))\n",
        "    # compile model\n",
        "    opt = SGD(lr=0.01, momentum=0.9)\n",
        "    model.compile(optimizer=opt, loss='binary_crossentropy', metrics=[fbeta])\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oaQXLQxdeCWM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# plot diagnostic learning curves\n",
        "def summarize_diagnostics(history, figname):\n",
        "    # plot loss\n",
        "#     pyplot.subplot(211)\n",
        "#     pyplot.figure()\n",
        "    \n",
        "    pyplot.plot(history.history['loss'], color='blue', label='train_loss')\n",
        "    pyplot.plot(history.history['val_loss'], color='orange', label='test_loss')\n",
        "    \n",
        "    # plot accuracy\n",
        "#     pyplot.subplot(212)\n",
        "#     pyplot.title('Fbeta')\n",
        "    pyplot.plot(history.history['fbeta'], color='blue', label='train_fbeta_score')\n",
        "    pyplot.plot(history.history['val_fbeta'], color='orange', label='test_fbeta_score')\n",
        "    \n",
        "    pyplot.title(figname+': Cross Entropy Loss and Fbeta Score')\n",
        "    pyplot.legend()\n",
        "    pyplot.xlabel('Epochs')\n",
        "    \n",
        "    # save plot to file\n",
        "    filename = folder_path + '/' + sys.argv[0].split('/')[-1] + '_' + figname\n",
        "    pyplot.savefig(filename + '_plot.png')\n",
        "    pyplot.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3p8-3IcLeCWQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# run the test harness for evaluating a model\n",
        "def run_test_harness(model, figname, epochs, height_shift_range=0.0, width_shift_range=0.0, shear_range=0.0, hor_flip=False, vert_flip=False, rot_range=0, featurewise_center=False):\n",
        "    # load dataset\n",
        "    trainX, trainY, testX, testY = load_saved_dataset()\n",
        "    # create data generator\n",
        "    if featurewise_center:\n",
        "        datagen = ImageDataGenerator(featurewise_center = True, height_shift_range=height_shift_range, width_shift_range=width_shift_range, shear_range=shear_range, horizontal_flip=hor_flip, vertical_flip=vert_flip, rotation_range=rot_range)\n",
        "        # specify imagenet mean values for centering\n",
        "        datagen.mean = [123.68, 116.779, 103.939]\n",
        "    else:\n",
        "        datagen = ImageDataGenerator(rescale=1.0/255.0, height_shift_range=height_shift_range, width_shift_range=width_shift_range, shear_range=shear_range, horizontal_flip=hor_flip, vertical_flip=vert_flip, rotation_range=rot_range)\n",
        "    # prepare iterators\n",
        "    train_it = datagen.flow(trainX, trainY, batch_size=128)\n",
        "    test_it = datagen.flow(testX, testY, batch_size=128)\n",
        "    \n",
        "    # fit model\n",
        "    history = model.fit_generator(train_it, steps_per_epoch=len(train_it),\n",
        "        validation_data=test_it, validation_steps=len(test_it), epochs=epochs, verbose=1)\n",
        "    # evaluate model\n",
        "    loss, fbeta = model.evaluate_generator(test_it, steps=len(test_it), verbose=1)\n",
        "    print('> loss=%.3f, fbeta=%.3f' % (loss, fbeta))\n",
        "    # learning curves\n",
        "    summarize_diagnostics(history, figname)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hq0ZxmaZeCWU",
        "colab_type": "code",
        "outputId": "9c79bb83-9f84-4b80-98b0-9729f52ed9a1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 469
        }
      },
      "source": [
        "# entry point, run the test harness\n",
        "model = define_baseline_model()\n",
        "run_test_harness(model, 'Baseline', 50)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_get_default_graph\u001b[0;34m()\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow' has no attribute 'get_default_graph'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-69-e8fcc045be4e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdefine_baseline_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mrun_test_harness\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Baseline'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-65-3227e5f8ec1c>\u001b[0m in \u001b[0;36mdefine_baseline_model\u001b[0;34m(in_shape, out_shape)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdefine_baseline_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m60\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m80\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m205\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mConv2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_initializer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'he_uniform'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'same'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0min_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mConv2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_initializer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'he_uniform'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'same'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMaxPooling2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/sequential.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, layers, name)\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSequential\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_build_input_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/network.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m             \u001b[0;31m# Subclassed network\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_subclassed_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_base_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/network.py\u001b[0m in \u001b[0;36m_init_subclassed_network\u001b[0;34m(self, name, **kwargs)\u001b[0m\n\u001b[1;32m    298\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_init_subclassed_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 300\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_base_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    301\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_graph_network\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_expects_training_arg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhas_arg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'training'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/network.py\u001b[0m in \u001b[0;36m_base_init\u001b[0;34m(self, name, trainable, dtype)\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m             \u001b[0mprefix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m             \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprefix\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_uid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprefix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mget_uid\u001b[0;34m(prefix)\u001b[0m\n\u001b[1;32m     84\u001b[0m     \"\"\"\n\u001b[1;32m     85\u001b[0m     \u001b[0;32mglobal\u001b[0m \u001b[0m_GRAPH_UID_DICTS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m     \u001b[0mgraph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mgraph\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_GRAPH_UID_DICTS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0m_GRAPH_UID_DICTS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdefaultdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_get_default_graph\u001b[0;34m()\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m         raise RuntimeError(\n\u001b[0;32m---> 69\u001b[0;31m             \u001b[0;34m'It looks like you are trying to use '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m             \u001b[0;34m'a version of multi-backend Keras that '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m             \u001b[0;34m'does not support TensorFlow 2.0. We recommend '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: It looks like you are trying to use a version of multi-backend Keras that does not support TensorFlow 2.0. We recommend using `tf.keras`, or alternatively, downgrading to TensorFlow 1.14."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d8pr6OlseCWZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define cnn model\n",
        "def define_bl_dropout_model(in_shape=(60, 80, 3), out_shape=205):\n",
        "    model = Sequential()\n",
        "    model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=in_shape))\n",
        "    model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "    model.add(MaxPooling2D((2, 2)))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "    model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "    model.add(MaxPooling2D((2, 2)))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "    model.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "    model.add(MaxPooling2D((2, 2)))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(out_shape, activation='sigmoid'))\n",
        "    # compile model\n",
        "    opt = SGD(lr=0.01, momentum=0.9)\n",
        "    model.compile(optimizer=opt, loss='binary_crossentropy', metrics=[fbeta])\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k8uhB-SzeCWc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# entry point, run the test harness for dropout model without augmentation\n",
        "model = define_bl_dropout_model()\n",
        "run_test_harness(model, 'Bl_Dropout', 200)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yz6J6eR9eCWf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# entry point, run the test harness for baseline model with augmentation\n",
        "model = define_baseline_model()\n",
        "run_test_harness(model, 'Bl_Img_Aug', 200, 0.1, 0.1, 10, True, True, 90)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V7r9NPU9eCWi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define cnn model\n",
        "def define_vgg_model(in_shape=(60, 80, 3), out_shape=205, model_trainable=False):\n",
        "    # load model\n",
        "    model = VGG16(include_top=False, input_shape=in_shape)\n",
        "    # mark loaded layers as not trainable\n",
        "    for layer in model.layers:\n",
        "        layer.trainable = False\n",
        "    if model_trainable:\n",
        "        # allow last vgg block to be trainable\n",
        "        model.get_layer('block5_conv1').trainable = True\n",
        "        model.get_layer('block5_conv2').trainable = True\n",
        "        model.get_layer('block5_conv3').trainable = True\n",
        "        model.get_layer('block5_pool').trainable = True\n",
        "    # add new classifier layers\n",
        "    flat1 = Flatten()(model.layers[-1].output)\n",
        "    class1 = Dense(128, activation='relu', kernel_initializer='he_uniform')(flat1)\n",
        "    output = Dense(out_shape, activation='sigmoid')(class1)\n",
        "    # define new model\n",
        "    model = Model(inputs=model.inputs, outputs=output)\n",
        "    # compile model\n",
        "    opt = SGD(lr=0.01, momentum=0.9)\n",
        "    model.compile(optimizer=opt, loss='binary_crossentropy', metrics=[fbeta])\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "18UzNHVdeCWm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# entry point, run the test harness for vgg model without augmentation\n",
        "model = define_vgg_model()\n",
        "run_test_harness(model, 'VGG', epochs=20, featurewise_center = True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7pQ5o4H5eCWp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# entry point, run the test harness for baseline model with augmentation\n",
        "model = define_vgg_model()\n",
        "run_test_harness(model, 'VGG_fine_tune', 50, featurewise_center = True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0uIduGO7eCWs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# entry point, run the test harness for baseline model with augmentation\n",
        "model = define_vgg_model()\n",
        "run_test_harness(model, 'VGG_Img_Aug_fine_tune', 50, 0.1, 0.1, 10, True, True, 90, featurewise_center = True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dYOYrVfweCWy",
        "colab_type": "code",
        "outputId": "6da2a95f-c535-438d-8dd2-ad45e3c5fb06",
        "colab": {}
      },
      "source": [
        "l=np.linspace(0,1,11)\n",
        "# fig,ax=pyplot.figure(figsize=(6,4))\n",
        "pyplot.figure()\n",
        "pyplot.plot(range(11), l, label=['line'])\n",
        "pyplot.plot(range(11,0,-1), l, label=['line_rev'])\n",
        "pyplot.xlabel('Epochs')\n",
        "pyplot.legend()\n",
        "# pyplot.close()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7fb2e6cb63c8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 217
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}