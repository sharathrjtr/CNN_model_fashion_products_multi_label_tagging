{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN classifier for multi label tagging of Myntra fashion products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import PIL\n",
    "import keras\n",
    "\n",
    "from keras.preprocessing.image import load_img, img_to_array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/sharathrjtr/CNN_model_fashion_products_multi_label_tagging.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import kaggle\n",
    "# os.environ['KAGGLE_USERNAME'] = \"sharathrjtr\"\n",
    "# os.environ['KAGGLE_KEY'] = \"\"#\"d35c14881c49c76dfc844f0740236ad1\"\n",
    "# upload your kaggle.json file. If you don't have it then you can get it by clicking \"Create New API Token\" under your kaggle Account/Profile/API\n",
    "os.environ['KAGGLE_CONFIG_DIR']='/content/'\n",
    "!kaggle datasets download -d paramaggarwal/fashion-product-images-small\n",
    "# !rm -r fashion-product-images-small.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanup_csv_mapping(mapping_csv):\n",
    "    # articleType can be used to find subCategory and masterCategory. \n",
    "    # Year specifies particular year the product is made, productDisplayName is something unique to the product and not a generalization.\n",
    "    # Hence, we are dropping masterCategory, subCartegory, year and productDisplayName columns from the data frame.\n",
    "    mapping_csv.drop(['masterCategory', 'subCategory', 'year', 'productDisplayName'], axis=1, inplace=True)\n",
    "\n",
    "    # Drop the samples which don't have any value in any of the columns.\n",
    "    mapping_csv.dropna(inplace=True)\n",
    "    mapping_csv.head()\n",
    "    \n",
    "    return mapping_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a list of tags available among gender, articleType, baseColour, season and usage\n",
    "# generate a mapping from tags to integers and integers to tags\n",
    "def extract_tags_mapping(mapping_csv):\n",
    "    labels = set()\n",
    "    \n",
    "    for index, row in mapping_csv.iterrows():\n",
    "        fileid = row['id']\n",
    "        gender = row['gender']\n",
    "        article_type = row['articleType']\n",
    "        base_colour = row['baseColour']\n",
    "        season = row['season']\n",
    "        usage = row['usage']\n",
    "        \n",
    "        labels.update([gender, article_type, base_colour, season, usage])\n",
    "    print('Total labels:', len(labels))\n",
    "\n",
    "    # convert the labels to a list and sort them alphabetically\n",
    "    labels = list(labels)\n",
    "    # order set alphabetically\n",
    "    labels.sort()\n",
    "    \n",
    "    # create dictionary that maps labels to integers so that we can encode the training dataset for modeling.\n",
    "    # create a dictionary with reverse mapping from integers to string tag values, so later when the model makes a prediction, we can turn it into something readable.\n",
    "    labels_map = {labels[i]: i for i in range(len(labels))}\n",
    "    inv_labels_map = {i:labels[i] for i in range(len(labels))}\n",
    "    \n",
    "    return labels_map, inv_labels_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the training images filename and labels for all images.\n",
    "def extract_img_ids_labels(mapping_csv):\n",
    "    image_ids = []\n",
    "    image_labels = dict()\n",
    "    for index, row in mapping_csv.iterrows():\n",
    "        fileid = row['id']\n",
    "        gender = row['gender']\n",
    "        article_type = row['articleType']\n",
    "        base_colour = row['baseColour']\n",
    "        season = row['season']\n",
    "        usage = row['usage']\n",
    "        \n",
    "        if os.path.exists('myntradataset/images/'+str(fileid)+'.jpg'):\n",
    "            image_ids.append(fileid)\n",
    "            image_labels[fileid] = [gender, article_type, base_colour, season, usage]\n",
    "    \n",
    "    print('Number of train files: ', len(image_ids))\n",
    "    \n",
    "    return image_ids, image_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a one hot encoding for one list of tags\n",
    "def one_hot_encode(tags, mapping):\n",
    "    # create empty vector\n",
    "    encoding = np.zeros(len(mapping), dtype='uint8')\n",
    "    # mark 1 for each tag in the vector\n",
    "    for tag in tags:\n",
    "        encoding[mapping[tag]] = 1\n",
    "    return encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load images and extract labels in one hot encode form\n",
    "def load_dataset(image_ids, image_labels, tag_mapping):\n",
    "    images, targets = list(), list()\n",
    "    # enumerate file in the directory\n",
    "    for filename in image_ids:\n",
    "        # load image\n",
    "        image = load_img(os.path.join('myntradataset/images', str(filename)+'.jpg'), target_size=(60,80))\n",
    "        # convert to numpy array\n",
    "        image = img_to_array(image, dtype='uint8')\n",
    "        # get tags\n",
    "        tags = image_labels[filename]\n",
    "        # one hot encode tags\n",
    "        target = one_hot_encode(tags, tag_mapping)\n",
    "        # store train image and tags\n",
    "        images.append(image)\n",
    "        targets.append(target)\n",
    "    \n",
    "    X = np.asarray(images, dtype='uint8')\n",
    "    y = np.asarray(targets, dtype='uint8')\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(44446, 10)\n",
      "(44101, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>gender</th>\n",
       "      <th>articleType</th>\n",
       "      <th>baseColour</th>\n",
       "      <th>season</th>\n",
       "      <th>usage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15970</td>\n",
       "      <td>Men</td>\n",
       "      <td>Shirts</td>\n",
       "      <td>Navy Blue</td>\n",
       "      <td>Fall</td>\n",
       "      <td>Casual</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>39386</td>\n",
       "      <td>Men</td>\n",
       "      <td>Jeans</td>\n",
       "      <td>Blue</td>\n",
       "      <td>Summer</td>\n",
       "      <td>Casual</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>59263</td>\n",
       "      <td>Women</td>\n",
       "      <td>Watches</td>\n",
       "      <td>Silver</td>\n",
       "      <td>Winter</td>\n",
       "      <td>Casual</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21379</td>\n",
       "      <td>Men</td>\n",
       "      <td>Track Pants</td>\n",
       "      <td>Black</td>\n",
       "      <td>Fall</td>\n",
       "      <td>Casual</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>53759</td>\n",
       "      <td>Men</td>\n",
       "      <td>Tshirts</td>\n",
       "      <td>Grey</td>\n",
       "      <td>Summer</td>\n",
       "      <td>Casual</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id gender  articleType baseColour  season   usage\n",
       "0  15970    Men       Shirts  Navy Blue    Fall  Casual\n",
       "1  39386    Men        Jeans       Blue  Summer  Casual\n",
       "2  59263  Women      Watches     Silver  Winter  Casual\n",
       "3  21379    Men  Track Pants      Black    Fall  Casual\n",
       "4  53759    Men      Tshirts       Grey  Summer  Casual"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_filename = 'myntradataset/styles.csv'\n",
    "# Read the csv file and clean up the file to extract relevant data\n",
    "# productDisplayName column consist of extra commas for few row. \n",
    "# These were manually removed as it can result in error during reading of the file\n",
    "mapping_csv = pd.read_csv(filename)\n",
    "print(mapping_csv.shape)\n",
    "\n",
    "mapping_csv = cleanup_csv_mapping(mapping_csv)\n",
    "print(mapping_csv.shape)\n",
    "mapping_csv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total labels: 205\n",
      "Number of train files:  44096\n",
      "(44096, 60, 80, 3) (44096, 205)\n"
     ]
    }
   ],
   "source": [
    "# extract mapping from labels to indices and indices to labels\n",
    "labels_to_idx, idx_to_labels = extract_tags_mapping(mapping_csv)\n",
    "\n",
    "# extract the images filename and tags for training dataset\n",
    "train_ids, train_labels = extract_img_ids_labels(mapping_csv)\n",
    "\n",
    "# load the dataset, the actual images and labels for each image with one-hot encoding\n",
    "train_images, train_tags = load_dataset(train_ids, train_labels, labels_to_idx)\n",
    "print(train_images.shape, train_tags.shape)\n",
    "\n",
    "# Total size of image loaded will be about 60*80*3*44101*8 / (1000000000*8) = 0.635GB\n",
    "# save both arrays to one file in compressed format\n",
    "np.savez_compressed('myntra_train_data.npz', train_images, train_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "# baseline model for the planet dataset\n",
    "import sys\n",
    "from matplotlib import pyplot\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import fbeta_score\n",
    "\n",
    "import keras\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras import backend\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_saved_dataset():\n",
    "    data = np.load('myntra_train_data.npz')\n",
    "    X, y = data['arr_0'], data['arr_1']\n",
    "    trainX, testX, trainY, testY = train_test_split(X, y, test_size = 0.3, random_state = 1)\n",
    "    print(trainX.shape, trainY.shape, testX.shape, testY.shape)\n",
    "    \n",
    "    return trainX, trainY, testX, testY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    " # calculate fbeta score for multi-class/label classification\n",
    "def fbeta(y_true, y_pred, beta=2):\n",
    "    # clip predictions\n",
    "    y_pred = keras.backend.clip(y_pred, 0, 1)\n",
    "    # calculate elements\n",
    "    tp = keras.backend.sum(keras.backend.round(keras.backend.clip(y_true * y_pred, 0, 1)), axis=1)\n",
    "    fp = keras.backend.sum(keras.backend.round(keras.backend.clip(y_pred - y_true, 0, 1)), axis=1)\n",
    "    fn = keras.backend.sum(keras.backend.round(keras.backend.clip(y_true - y_pred, 0, 1)), axis=1)\n",
    "    # calculate precision\n",
    "    p = tp / (tp + fp + keras.backend.epsilon())\n",
    "    # calculate recall\n",
    "    r = tp / (tp + fn + keras.backend.epsilon())\n",
    "    # calculate fbeta, averaged across each class\n",
    "    bb = beta ** 2\n",
    "    fbeta_score = keras.backend.mean((1 + bb) * (p * r) / (bb * p + r + keras.backend.epsilon()))\n",
    "    return fbeta_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30867, 60, 80, 3) (30867, 205) (13229, 60, 80, 3) (13229, 205)\n",
      "All Ones: train=0.111, test=0.111\n",
      "All Ones (keras): train=0.111, test=0.111\n"
     ]
    }
   ],
   "source": [
    "\n",
    "trainX, trainY, testX, testY = load_saved_dataset()\n",
    "\n",
    "# make all one predictions\n",
    "train_yhat = np.asarray([np.ones(trainY.shape[1]) for _ in range(trainY.shape[0])])\n",
    "test_yhat = np.asarray([np.ones(testY.shape[1]) for _ in range(testY.shape[0])])\n",
    "# evaluate predictions\n",
    "train_score = fbeta_score(trainY, train_yhat, 2, average='samples')\n",
    "test_score = fbeta_score(testY, test_yhat, 2, average='samples')\n",
    "print('All Ones: train=%.3f, test=%.3f' % (train_score, test_score))\n",
    "\n",
    "# evaluate predictions with keras\n",
    "train_score = fbeta(keras.backend.variable(trainY), keras.backend.variable(train_yhat))\n",
    "test_score = fbeta(keras.backend.variable(testY), keras.backend.variable(test_yhat))\n",
    "\n",
    "print('All Ones (keras): train=%.3f, test=%.3f' % (keras.backend.eval(train_score), keras.backend.eval(test_score)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define cnn model\n",
    "def define_baseline_model(in_shape=(60,80, 3), out_shape=205):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=in_shape))\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "    model.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n",
    "    model.add(Dense(out_shape, activation='sigmoid'))\n",
    "    # compile model\n",
    "    opt = SGD(lr=0.01, momentum=0.9)\n",
    "    model.compile(optimizer=opt, loss='binary_crossentropy', metrics=[fbeta])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot diagnostic learning curves\n",
    "def summarize_diagnostics(history, figname):\n",
    "    # plot loss\n",
    "#     pyplot.subplot(211)\n",
    "#     pyplot.figure()\n",
    "    \n",
    "    pyplot.plot(history.history['loss'], color='blue', label='train_loss')\n",
    "    pyplot.plot(history.history['val_loss'], color='orange', label='test_loss')\n",
    "    \n",
    "    # plot accuracy\n",
    "#     pyplot.subplot(212)\n",
    "#     pyplot.title('Fbeta')\n",
    "    pyplot.plot(history.history['fbeta'], color='blue', label='train_fbeta_score')\n",
    "    pyplot.plot(history.history['val_fbeta'], color='orange', label='test_fbeta_score')\n",
    "    \n",
    "    pyplot.title(figname+': Cross Entropy Loss and Fbeta Score')\n",
    "    pyplot.legend()\n",
    "    pyplot.xlabel('Epochs')\n",
    "    \n",
    "    # save plot to file\n",
    "    filename = sys.argv[0].split('/')[-1] + '_' + figname\n",
    "    pyplot.savefig(filename + '_plot.png')\n",
    "    pyplot.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the test harness for evaluating a model\n",
    "def run_test_harness(model, figname, epochs, height_shift_range=0.0, width_shift_range=0.0, shear_range=0.0, hor_flip=False, vert_flip=False, rot_range=0, featurewise_center=False):\n",
    "    # load dataset\n",
    "    trainX, trainY, testX, testY = load_saved_dataset()\n",
    "    # create data generator\n",
    "    if featurewise_center:\n",
    "        datagen = ImageDataGenerator(featurewise_center = True, height_shift_range=height_shift_range, width_shift_range=width_shift_range, shear_range=shear_range, horizontal_flip=hor_flip, vertical_flip=vert_flip, rotation_range=rot_range)\n",
    "        # specify imagenet mean values for centering\n",
    "        datagen.mean = [123.68, 116.779, 103.939]\n",
    "    else:\n",
    "        datagen = ImageDataGenerator(rescale=1.0/255.0, height_shift_range=height_shift_range, width_shift_range=width_shift_range, shear_range=shear_range, horizontal_flip=hor_flip, vertical_flip=vert_flip, rotation_range=rot_range)\n",
    "    # prepare iterators\n",
    "    train_it = datagen.flow(trainX, trainY, batch_size=128)\n",
    "    test_it = datagen.flow(testX, testY, batch_size=128)\n",
    "    \n",
    "    # fit model\n",
    "    history = model.fit_generator(train_it, steps_per_epoch=len(train_it),\n",
    "        validation_data=test_it, validation_steps=len(test_it), epochs=epochs, verbose=1)\n",
    "    # evaluate model\n",
    "    loss, fbeta = model.evaluate_generator(test_it, steps=len(test_it), verbose=1)\n",
    "    print('> loss=%.3f, fbeta=%.3f' % (loss, fbeta))\n",
    "    # learning curves\n",
    "    summarize_diagnostics(history, figname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30867, 60, 80, 3) (30867, 205) (13229, 60, 80, 3) (13229, 205)\n",
      "WARNING:tensorflow:From /home/sj/.virtualenvs/virtual-py3/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/sj/.virtualenvs/virtual-py3/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/sj/.virtualenvs/virtual-py3/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/sj/.virtualenvs/virtual-py3/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/sj/.virtualenvs/virtual-py3/lib/python3.5/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/sj/.virtualenvs/virtual-py3/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py:3376: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/sj/.virtualenvs/virtual-py3/lib/python3.5/site-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /home/sj/.virtualenvs/virtual-py3/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/sj/.virtualenvs/virtual-py3/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py:973: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "Epoch 1/50\n",
      "242/242 [==============================] - 47s 192ms/step - loss: 0.1202 - fbeta: 0.2573 - val_loss: 0.0650 - val_fbeta: 0.2117\n",
      "Epoch 2/50\n",
      "242/242 [==============================] - 35s 144ms/step - loss: 0.0640 - fbeta: 0.2862 - val_loss: 0.0633 - val_fbeta: 0.3043\n",
      "Epoch 3/50\n",
      "242/242 [==============================] - 35s 144ms/step - loss: 0.0621 - fbeta: 0.3286 - val_loss: 0.0614 - val_fbeta: 0.3866\n",
      "Epoch 4/50\n",
      "242/242 [==============================] - 35s 145ms/step - loss: 0.0599 - fbeta: 0.3629 - val_loss: 0.0593 - val_fbeta: 0.3886\n",
      "Epoch 5/50\n",
      "242/242 [==============================] - 36s 148ms/step - loss: 0.0576 - fbeta: 0.3926 - val_loss: 0.0572 - val_fbeta: 0.4360\n",
      "Epoch 6/50\n",
      "242/242 [==============================] - 36s 149ms/step - loss: 0.0553 - fbeta: 0.4218 - val_loss: 0.0546 - val_fbeta: 0.4172\n",
      "Epoch 7/50\n",
      "242/242 [==============================] - 36s 147ms/step - loss: 0.0531 - fbeta: 0.4497 - val_loss: 0.0528 - val_fbeta: 0.4641\n",
      "Epoch 8/50\n",
      "242/242 [==============================] - 36s 149ms/step - loss: 0.0511 - fbeta: 0.4728 - val_loss: 0.0508 - val_fbeta: 0.4741\n",
      "Epoch 9/50\n",
      "242/242 [==============================] - 36s 149ms/step - loss: 0.0493 - fbeta: 0.4941 - val_loss: 0.0492 - val_fbeta: 0.4724\n",
      "Epoch 10/50\n",
      "242/242 [==============================] - 36s 148ms/step - loss: 0.0478 - fbeta: 0.5146 - val_loss: 0.0477 - val_fbeta: 0.5253\n",
      "Epoch 11/50\n",
      "242/242 [==============================] - 36s 148ms/step - loss: 0.0465 - fbeta: 0.5302 - val_loss: 0.0467 - val_fbeta: 0.5505\n",
      "Epoch 12/50\n",
      "242/242 [==============================] - 36s 148ms/step - loss: 0.0455 - fbeta: 0.5438 - val_loss: 0.0457 - val_fbeta: 0.5433\n",
      "Epoch 13/50\n",
      "242/242 [==============================] - 36s 148ms/step - loss: 0.0445 - fbeta: 0.5552 - val_loss: 0.0448 - val_fbeta: 0.5414\n",
      "Epoch 14/50\n",
      "242/242 [==============================] - 36s 148ms/step - loss: 0.0436 - fbeta: 0.5641 - val_loss: 0.0442 - val_fbeta: 0.5699\n",
      "Epoch 15/50\n",
      "242/242 [==============================] - 36s 149ms/step - loss: 0.0430 - fbeta: 0.5734 - val_loss: 0.0432 - val_fbeta: 0.5807\n",
      "Epoch 16/50\n",
      "242/242 [==============================] - 36s 148ms/step - loss: 0.0422 - fbeta: 0.5827 - val_loss: 0.0426 - val_fbeta: 0.5737\n",
      "Epoch 17/50\n",
      "242/242 [==============================] - 36s 148ms/step - loss: 0.0416 - fbeta: 0.5905 - val_loss: 0.0426 - val_fbeta: 0.5886\n",
      "Epoch 18/50\n",
      "242/242 [==============================] - 36s 148ms/step - loss: 0.0410 - fbeta: 0.5965 - val_loss: 0.0422 - val_fbeta: 0.6105\n",
      "Epoch 19/50\n",
      "242/242 [==============================] - 36s 148ms/step - loss: 0.0405 - fbeta: 0.6023 - val_loss: 0.0409 - val_fbeta: 0.6049\n",
      "Epoch 20/50\n",
      "242/242 [==============================] - 36s 148ms/step - loss: 0.0400 - fbeta: 0.6072 - val_loss: 0.0415 - val_fbeta: 0.5858\n",
      "Epoch 21/50\n",
      "242/242 [==============================] - 36s 148ms/step - loss: 0.0395 - fbeta: 0.6130 - val_loss: 0.0405 - val_fbeta: 0.5927\n",
      "Epoch 22/50\n",
      "242/242 [==============================] - 35s 145ms/step - loss: 0.0389 - fbeta: 0.6186 - val_loss: 0.0405 - val_fbeta: 0.6078\n",
      "Epoch 23/50\n",
      "242/242 [==============================] - 35s 145ms/step - loss: 0.0385 - fbeta: 0.6242 - val_loss: 0.0394 - val_fbeta: 0.6280\n",
      "Epoch 24/50\n",
      "242/242 [==============================] - 36s 147ms/step - loss: 0.0381 - fbeta: 0.6280 - val_loss: 0.0389 - val_fbeta: 0.6224\n",
      "Epoch 25/50\n",
      "242/242 [==============================] - 36s 148ms/step - loss: 0.0376 - fbeta: 0.6340 - val_loss: 0.0391 - val_fbeta: 0.6298\n",
      "Epoch 26/50\n",
      "242/242 [==============================] - 35s 146ms/step - loss: 0.0373 - fbeta: 0.6374 - val_loss: 0.0384 - val_fbeta: 0.6145\n",
      "Epoch 27/50\n",
      "242/242 [==============================] - 35s 146ms/step - loss: 0.0370 - fbeta: 0.6402 - val_loss: 0.0382 - val_fbeta: 0.6311\n",
      "Epoch 28/50\n",
      "242/242 [==============================] - 35s 145ms/step - loss: 0.0366 - fbeta: 0.6451 - val_loss: 0.0380 - val_fbeta: 0.6319\n",
      "Epoch 29/50\n",
      "242/242 [==============================] - 35s 146ms/step - loss: 0.0363 - fbeta: 0.6476 - val_loss: 0.0378 - val_fbeta: 0.6331\n",
      "Epoch 30/50\n",
      "242/242 [==============================] - 36s 148ms/step - loss: 0.0360 - fbeta: 0.6514 - val_loss: 0.0380 - val_fbeta: 0.6203\n",
      "Epoch 31/50\n",
      "242/242 [==============================] - 36s 149ms/step - loss: 0.0357 - fbeta: 0.6530 - val_loss: 0.0370 - val_fbeta: 0.6351\n",
      "Epoch 32/50\n",
      "242/242 [==============================] - 35s 145ms/step - loss: 0.0353 - fbeta: 0.6578 - val_loss: 0.0366 - val_fbeta: 0.6296\n",
      "Epoch 33/50\n",
      "242/242 [==============================] - 35s 146ms/step - loss: 0.0349 - fbeta: 0.6625 - val_loss: 0.0367 - val_fbeta: 0.6563\n",
      "Epoch 34/50\n",
      "242/242 [==============================] - 36s 147ms/step - loss: 0.0347 - fbeta: 0.6634 - val_loss: 0.0362 - val_fbeta: 0.6484\n",
      "Epoch 35/50\n",
      "242/242 [==============================] - 35s 147ms/step - loss: 0.0345 - fbeta: 0.6669 - val_loss: 0.0359 - val_fbeta: 0.6432\n",
      "Epoch 36/50\n",
      "242/242 [==============================] - 35s 146ms/step - loss: 0.0341 - fbeta: 0.6699 - val_loss: 0.0359 - val_fbeta: 0.6355\n",
      "Epoch 37/50\n",
      "242/242 [==============================] - 35s 146ms/step - loss: 0.0339 - fbeta: 0.6724 - val_loss: 0.0358 - val_fbeta: 0.6549\n",
      "Epoch 38/50\n",
      "242/242 [==============================] - 35s 146ms/step - loss: 0.0337 - fbeta: 0.6740 - val_loss: 0.0359 - val_fbeta: 0.6312\n",
      "Epoch 39/50\n",
      "242/242 [==============================] - 35s 147ms/step - loss: 0.0334 - fbeta: 0.6771 - val_loss: 0.0355 - val_fbeta: 0.6679\n",
      "Epoch 40/50\n",
      "242/242 [==============================] - 35s 146ms/step - loss: 0.0333 - fbeta: 0.6799 - val_loss: 0.0352 - val_fbeta: 0.6602\n",
      "Epoch 41/50\n",
      "242/242 [==============================] - 35s 145ms/step - loss: 0.0330 - fbeta: 0.6816 - val_loss: 0.0349 - val_fbeta: 0.6547\n",
      "Epoch 42/50\n",
      "242/242 [==============================] - 35s 145ms/step - loss: 0.0327 - fbeta: 0.6853 - val_loss: 0.0353 - val_fbeta: 0.6583\n",
      "Epoch 43/50\n",
      "242/242 [==============================] - 35s 145ms/step - loss: 0.0325 - fbeta: 0.6876 - val_loss: 0.0348 - val_fbeta: 0.6654\n",
      "Epoch 44/50\n",
      "242/242 [==============================] - 35s 144ms/step - loss: 0.0323 - fbeta: 0.6881 - val_loss: 0.0345 - val_fbeta: 0.6750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45/50\n",
      "242/242 [==============================] - 35s 143ms/step - loss: 0.0322 - fbeta: 0.6906 - val_loss: 0.0343 - val_fbeta: 0.6696\n",
      "Epoch 46/50\n",
      "242/242 [==============================] - 35s 144ms/step - loss: 0.0319 - fbeta: 0.6919 - val_loss: 0.0340 - val_fbeta: 0.6697\n",
      "Epoch 47/50\n",
      "242/242 [==============================] - 35s 144ms/step - loss: 0.0318 - fbeta: 0.6941 - val_loss: 0.0347 - val_fbeta: 0.6442\n",
      "Epoch 48/50\n",
      "242/242 [==============================] - 35s 144ms/step - loss: 0.0315 - fbeta: 0.6984 - val_loss: 0.0339 - val_fbeta: 0.6803\n",
      "Epoch 49/50\n",
      "242/242 [==============================] - 35s 144ms/step - loss: 0.0312 - fbeta: 0.7002 - val_loss: 0.0338 - val_fbeta: 0.6721\n",
      "Epoch 50/50\n",
      "242/242 [==============================] - 35s 144ms/step - loss: 0.0311 - fbeta: 0.7021 - val_loss: 0.0336 - val_fbeta: 0.6873\n",
      "104/104 [==============================] - 5s 45ms/step\n",
      "> loss=0.034, fbeta=0.687\n"
     ]
    }
   ],
   "source": [
    "# entry point, run the test harness\n",
    "model = define_baseline_model()\n",
    "run_test_harness(model, 'Baseline', 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define cnn model\n",
    "def define_bl_dropout_model(in_shape=(60, 80, 3), out_shape=205):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=in_shape))\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "    model.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(out_shape, activation='sigmoid'))\n",
    "    # compile model\n",
    "    opt = SGD(lr=0.01, momentum=0.9)\n",
    "    model.compile(optimizer=opt, loss='binary_crossentropy', metrics=[fbeta])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# entry point, run the test harness for dropout model without augmentation\n",
    "model = define_bl_dropout_model()\n",
    "run_test_harness(model, 'Bl_Dropout', 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# entry point, run the test harness for baseline model with augmentation\n",
    "model = define_baseline_model()\n",
    "run_test_harness(model, 'Bl_Img_Aug', 200, 0.1, 0.1, 10, True, True, 90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define cnn model\n",
    "def define_vgg_model(in_shape=(60, 80, 3), out_shape=205, model_trainable=False):\n",
    "    # load model\n",
    "    model = VGG16(include_top=False, input_shape=in_shape)\n",
    "    # mark loaded layers as not trainable\n",
    "    for layer in model.layers:\n",
    "        layer.trainable = False\n",
    "    if model_trainable:\n",
    "        # allow last vgg block to be trainable\n",
    "        model.get_layer('block5_conv1').trainable = True\n",
    "        model.get_layer('block5_conv2').trainable = True\n",
    "        model.get_layer('block5_conv3').trainable = True\n",
    "        model.get_layer('block5_pool').trainable = True\n",
    "    # add new classifier layers\n",
    "    flat1 = Flatten()(model.layers[-1].output)\n",
    "    class1 = Dense(128, activation='relu', kernel_initializer='he_uniform')(flat1)\n",
    "    output = Dense(out_shape, activation='sigmoid')(class1)\n",
    "    # define new model\n",
    "    model = Model(inputs=model.inputs, outputs=output)\n",
    "    # compile model\n",
    "    opt = SGD(lr=0.01, momentum=0.9)\n",
    "    model.compile(optimizer=opt, loss='binary_crossentropy', metrics=[fbeta])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# entry point, run the test harness for vgg model without augmentation\n",
    "model = define_vgg_model()\n",
    "run_test_harness(model, 'VGG', epochs=20, featurewise_center = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# entry point, run the test harness for baseline model with augmentation\n",
    "model = define_vgg_model()\n",
    "run_test_harness(model, 'VGG_fine_tune', 50, featurewise_center = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# entry point, run the test harness for baseline model with augmentation\n",
    "model = define_vgg_model()\n",
    "run_test_harness(model, 'VGG_Img_Aug_fine_tune', 50, 0.1, 0.1, 10, True, True, 90, featurewise_center = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fb2e6cb63c8>"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "l=np.linspace(0,1,11)\n",
    "# fig,ax=pyplot.figure(figsize=(6,4))\n",
    "pyplot.figure()\n",
    "pyplot.plot(range(11), l, label=['line'])\n",
    "pyplot.plot(range(11,0,-1), l, label=['line_rev'])\n",
    "pyplot.xlabel('Epochs')\n",
    "pyplot.legend()\n",
    "# pyplot.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
